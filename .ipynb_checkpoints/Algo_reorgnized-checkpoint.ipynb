{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd02f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import subgraph, k_hop_subgraph, dense_to_sparse\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.nn.functional as FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb548356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    dataset=Planetoid(root='tmp/Cora', name='Cora')\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d288587",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_Extraction(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(GCN_Extraction,self).__init__()\n",
    "        self.conv1=GCNConv(num_features,16)\n",
    "        self.conv2=GCNConv(16, num_classes)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x=self.conv1(x,edge_index)\n",
    "        x=torch.relu(x)\n",
    "        x=self.conv2(x,edge_index)\n",
    "        return torch.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1ba4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_Victim(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(GCN_Victim,self).__init__()\n",
    "        self.conv1=GCNConv(num_features,128)\n",
    "        self.conv2=GCNConv(128,64)\n",
    "        self.conv3=GCNConv(64, 16)\n",
    "        self.conv4=GCNConv(16,num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x=self.conv1(x,edge_index)\n",
    "        x=torch.relu(x)\n",
    "        x=FF.dropout(x,training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x=torch.relu(x)\n",
    "        x=FF.dropout(x,training=self.training)\n",
    "        x=self.conv3(x,edge_index)\n",
    "        x=torch.relu(x)\n",
    "        x=self.conv4(x, edge_index)\n",
    "        return torch.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfc0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2hop_subgraph(data, min_size=100, max_size=150):\n",
    "    num_nodes=data.num_nodes\n",
    "\n",
    "    while True:\n",
    "        node_idx=torch.randint(0,num_nodes,(1,)).item()\n",
    "        subset, edge_index,_,_=k_hop_subgraph(node_idx, 2, data.edge_index, relabel_nodes=True)\n",
    "\n",
    "        if min_size<=subset.size(0)<=max_size:\n",
    "            As=torch.zeros((subset.size(0),subset.size(0)))\n",
    "            As[edge_index[0],edge_index[1]]=1\n",
    "\n",
    "            Xs=data.x[subset]\n",
    "\n",
    "            return As.numpy(), Xs.numpy(), node_idx, subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f3790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution(num_classes):\n",
    "    F=[]\n",
    "    M=[]\n",
    "    for c in range(num_classes):\n",
    "        class_nodes=data.x[labels==c]\n",
    "\n",
    "        feature_counts=class_nodes.sum(dim=0).numpy()\n",
    "        feature_distribution=feature_counts/feature_counts.sum()\n",
    "        F.append(feature_distribution)\n",
    "\n",
    "        num_features_per_node=class_nodes.sum(dim=1).numpy()\n",
    "        feature_count_distribution=np.bincount(num_features_per_node.astype(int),minlength=num_features)\n",
    "        M.append(feature_count_distribution/feature_count_distribution.sum())\n",
    "        \n",
    "    return F,M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848164c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateSample(Fc, Mc, As):\n",
    "    num_nodes=As.shape[0]\n",
    "    Ac=torch.ones((num_nodes,num_nodes))\n",
    "    Xc=torch.zeros(num_nodes, len(Fc))\n",
    "\n",
    "    for i in range(num_nodes):\n",
    "        m=np.random.choice(np.arange(len(Mc)),p=Mc)\n",
    "        features=np.random.choice(len(Fc),size=m,replace=False,p=Fc)\n",
    "        Xc[i,features]=1\n",
    "\n",
    "    return Ac.numpy(), Xc.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea30e7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubgraphSamplingAlgorithm(Gs, api_function, F, M, n, C):\n",
    "    As, Xs=Gs\n",
    "    num_nodes=As.shape[0]\n",
    "    SA=[As]\n",
    "    SX=[Xs]\n",
    "    SL=[api_function(Xs,As)]\n",
    "\n",
    "    for i in range(n):\n",
    "        for c in range(C):\n",
    "            Ac, Xc=GenerateSample(F[c],M[c],As)\n",
    "            SA.append(Ac)\n",
    "            SX.append(Xc)\n",
    "            SL.append(api_function(Xc,Ac))\n",
    "\n",
    "    AG_list=[dense_to_sparse(torch.tensor(a))[0] for a in SA]\n",
    "    XG=torch.vstack([torch.tensor(x) for x in SX])\n",
    "\n",
    "    SL=torch.tensor(SL,dtype=torch.long).view(-1)\n",
    "\n",
    "\n",
    "    valid_mask = SL >= 0\n",
    "    SL = SL[valid_mask]\n",
    "    SL = SL[:XG.shape[0]]\n",
    "\n",
    "    \n",
    "    AG_combined=torch.cat([edge_index+i*num_nodes for i, edge_index in enumerate (AG_list)], dim=1)\n",
    "    num_nodes_combined=XG.shape[0]\n",
    "\n",
    "\n",
    "    \n",
    "    g=GCN_Extraction(XG.shape[1], C)\n",
    "    optimizer=optim.Adam(g.parameters(),lr=0.01)\n",
    "    loss_fn=nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    g.train()\n",
    "    for epoch in range(200):\n",
    "        optimizer.zero_grad()\n",
    "        out=g(XG,AG_combined)\n",
    "        loss=loss_fn(out,SL)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbcadb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_out_class(features, adjacency_matrix):\n",
    "    features_tensor=torch.tensor(features,dtype=torch.float)\n",
    "    adjacency_tensor=torch.tensor(adjacency_matrix,dtype=torch.long)\n",
    "\n",
    "    if adjacency_tensor.ndim==2 and adjacency_tensor.shape[0]==adjacency_tensor.shape[1]:\n",
    "        adjacency_tensor=torch.nonzero(adjacency_tensor, as_tuple=False).t()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits=f(features_tensor, adjacency_tensor)\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "    \n",
    "    return predictions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b614d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_out_vector(features, adjacency_matrix):\n",
    "    features_tensor=torch.tensor(features,dtype=torch.float)\n",
    "    adjacency_tensor=torch.tensor(adjacency_matrix,dtype=torch.long)\n",
    "\n",
    "    if adjacency_tensor.ndim==2 and adjacency_tensor.shape[0]==adjacency_tensor.shape[1]:\n",
    "        adjacency_tensor=torch.nonzero(adjacency_tensor, as_tuple=False).t()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        logits=f(features_tensor, adjacency_tensor)\n",
    "\n",
    "    return logits.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d65d348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(original_model, extracted_model, test_features, test_adj):\n",
    "    original_preds_labels=api_out_class(test_features, test_adj)\n",
    "    test_adj_tensor=torch.tensor(test_adj,dtype=torch.float)\n",
    "    edge_index, edge_weight=dense_to_sparse(test_adj_tensor)\n",
    "    with torch.no_grad():\n",
    "        extracted_preds=extracted_model(torch.tensor(test_features,dtype=torch.float),edge_index)\n",
    "        \n",
    "    extracted_preds_labels=extracted_preds.argmax(dim=1).numpy()\n",
    "\n",
    "    f=accuracy_score(original_preds_labels, extracted_preds_labels)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c82f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fidelity(extraction_model,times):\n",
    "    list_out=[]\n",
    "    for i in range(times):\n",
    "        pred=evaluate(api_function,extraction_model,Xs,As)\n",
    "        list_out.append(pred)\n",
    "    \n",
    "    return sum(list_out)/len(list_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8100c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_center_node_in_subgraph(center_global_idx, node_mapping):\n",
    "    center_subgraph_idx = node_mapping.tolist().index(center_global_idx)\n",
    "    return center_subgraph_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08190b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_nodes(Gc, api_out_vector, F, M, C, rho):\n",
    "    A,X=Gc\n",
    "    L=api_out_vector(X, A)\n",
    "    center_idx=find_center_node_in_subgraph(center_node,node_mapping)\n",
    "    for node in range(A.shape[0]):\n",
    "        if node!=center_idx:\n",
    "            Dn=L[node]-L[center_idx]\n",
    "            for c in range(C):\n",
    "                if Dn[c]>0:\n",
    "                    num_new_nodes=int(Dn[c]*rho*A[node].sum())\n",
    "                    for _ in range(num_new_nodes):\n",
    "                        new_node = A.shape[0]\n",
    "                        \n",
    "                        new_adj_row = np.zeros((1, A.shape[1]))\n",
    "                        A = np.vstack([A, new_adj_row])\n",
    "                        \n",
    "                        new_adj_col = np.zeros((A.shape[0], 1))\n",
    "                        A = np.hstack([A, new_adj_col])\n",
    "                        \n",
    "                        A[node, new_node] = 1\n",
    "                        A[new_node, node] = 1\n",
    "                        \n",
    "                        feature_count = np.random.choice(len(M[c]), p=M[c])  \n",
    "                        new_features = np.zeros_like(F[c])\n",
    "                        chosen_features = np.random.choice(len(F[c]), size=feature_count, p=F[c])  \n",
    "                        new_features[chosen_features] = 1  \n",
    "\n",
    "                        X = np.vstack([X, new_features])\n",
    "    Gc=(A,X)\n",
    "    return Gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630a1c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d66cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7002a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_function=api_out_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e087e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=data.y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8583c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a697e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features=data.x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d4c85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "F,M=get_distribution(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e2820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "runturns=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c03f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "As, Xs, center_node, node_mapping=get_2hop_subgraph(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c18de33",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gs=(As,Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=GCN_Victim(Xs.shape[1],dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f21aab2-b4fe-4554-ae00-edf916102294",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gs_with_approximated_nodes = approximate_nodes(Gs, api_out_vector, F, M, C=dataset.num_classes,rho=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b1d78-aa6f-43d8-aade-26cae5e7fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(f\"The size of tensors with algo1{Gs[0].shape,Gs[1].shape}\")\n",
    "    print(f\"The size of tensors with algo2{Gs_with_approximated_nodes[0].shape,Gs_with_approximated_nodes[1].shape}\")\n",
    "\n",
    "    Extraction_algo1=SubgraphSamplingAlgorithm(Gs, api_function, F, M, n=10, C=dataset.num_classes)\n",
    "    Extraction_algo2=SubgraphSamplingAlgorithm(Gs_with_approximated_nodes, api_function, F, M, n=10, C=dataset.num_classes)\n",
    "    \n",
    "    print(f\"Fidelity of the extracted model compared to the original model by algorithm 1: {get_fidelity(Extraction_algo1,runturns):.4f}\")\n",
    "    print(f\"Fidelity of the extracted model compared to the original model by algorithm 2: {get_fidelity(Extraction_algo2,runturns):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39262ac-732c-462e-b08b-5da0560e5afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff6d96d-3f34-4b07-b8ea-934b09aab7c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
