{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "3bd02f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import subgraph, k_hop_subgraph, dense_to_sparse\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.nn.functional as FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "eb548356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    dataset=Planetoid(root='tmp/Cora', name='Cora')\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "8d288587",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_Extraction(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(GCN_Extraction,self).__init__()\n",
    "        self.conv1=GCNConv(num_features,16)\n",
    "        self.conv2=GCNConv(16, num_classes)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x=self.conv1(x,edge_index)\n",
    "        x=torch.relu(x)\n",
    "        x=self.conv2(x,edge_index)\n",
    "        return torch.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "cb1ba4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_Victim(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(GCN_Victim,self).__init__()\n",
    "        self.conv1=GCNConv(num_features,128)\n",
    "        self.conv2=GCNConv(128,64)\n",
    "        self.conv3=GCNConv(64, 16)\n",
    "        self.conv4=GCNConv(16,num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x=self.conv1(x,edge_index)\n",
    "        x=torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x=torch.relu(x)\n",
    "        x=self.conv3(x,edge_index)\n",
    "        x=torch.relu(x)\n",
    "        x=self.conv4(x, edge_index)\n",
    "        return torch.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "45e6d58a-affb-495d-9c7b-f82a5477fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Victim(model, data, epoches=200, lr=0.01, weight_decay=5e-4):\n",
    "    optimizer=optim.Adam(model.parameters(),lr=lr, weight_decay=weight_decay)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epoches):\n",
    "        optimizer.zero_grad()\n",
    "        out=model(data.x, data.edge_index)\n",
    "        loss=FF.nll_loss(out[data.train_mask],data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 10 ==0:\n",
    "            print(f\"Epoch {epoch+10}, Loss: {loss.item():.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "7a685305-5155-4648-a210-4a8685239ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Extraction(model,features, adjacency_matrix, labels, epoches=400, lr=0.01, weight_decay=5e-4):\n",
    "    optimizer=optim.Adam(model.parameters(),lr=lr, weight_decay=weight_decay)\n",
    "    model.train()\n",
    "\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(epoches):\n",
    "        optimizer.zero_grad()\n",
    "        out=model(features, adjacency_matrix)\n",
    "        loss=FF.nll_loss(out,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        if epoch % 10 ==0:\n",
    "            print(f\"Epoch {epoch+10}, Loss: {loss.item():.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "9bfc0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2hop_subgraph(data, min_size=100, max_size=150):\n",
    "    num_nodes=data.num_nodes\n",
    "\n",
    "    while True:\n",
    "        node_idx=torch.randint(0,num_nodes,(1,)).item()\n",
    "        subset, edge_index,_,_=k_hop_subgraph(node_idx, 2, data.edge_index, relabel_nodes=True)\n",
    "\n",
    "        if min_size<=subset.size(0)<=max_size:\n",
    "            As=torch.zeros((subset.size(0),subset.size(0)))\n",
    "            As[edge_index[0],edge_index[1]]=1\n",
    "\n",
    "            Xs=data.x[subset]\n",
    "\n",
    "            return As.numpy(), Xs.numpy(), node_idx, subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "c8f3790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution(num_classes):\n",
    "    F=[]\n",
    "    M=[]\n",
    "    for c in range(num_classes):\n",
    "        class_nodes=data.x[labels==c]\n",
    "\n",
    "        feature_counts=class_nodes.sum(dim=0).numpy()\n",
    "        feature_distribution=feature_counts/feature_counts.sum()\n",
    "        F.append(feature_distribution)\n",
    "\n",
    "        num_features_per_node=class_nodes.sum(dim=1).numpy()\n",
    "        feature_count_distribution=np.bincount(num_features_per_node.astype(int),minlength=num_features)\n",
    "        M.append(feature_count_distribution/feature_count_distribution.sum())\n",
    "        \n",
    "    return F,M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "848164c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateSample(Fc, Mc, As):\n",
    "    num_nodes=As.shape[0]\n",
    "    Ac=torch.ones((num_nodes,num_nodes))\n",
    "    Xc=torch.zeros(num_nodes, len(Fc))\n",
    "\n",
    "    for i in range(num_nodes):\n",
    "        m=np.random.choice(np.arange(len(Mc)),p=Mc)\n",
    "        features=np.random.choice(len(Fc),size=m,replace=False,p=Fc)\n",
    "        Xc[i,features]=1\n",
    "\n",
    "    return Ac.numpy(), Xc.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "ea30e7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubgraphSamplingAlgorithm(Gs,F, M, n, C):\n",
    "    As, Xs=Gs\n",
    "    num_nodes=As.shape[0]\n",
    "    SA=[As]\n",
    "    SX=[Xs]\n",
    "    SL=[api_out_class(Xs,As)]\n",
    "\n",
    "    for i in range(n):\n",
    "        for c in range(C):\n",
    "            Ac, Xc=GenerateSample(F[c],M[c],As)\n",
    "            SA.append(Ac)\n",
    "            SX.append(Xc)\n",
    "            SL.append(api_out_class(Xc,Ac))\n",
    "\n",
    "    AG_list=[dense_to_sparse(torch.tensor(a))[0] for a in SA]\n",
    "    XG=torch.vstack([torch.tensor(x) for x in SX])\n",
    "\n",
    "    SL=torch.tensor(SL,dtype=torch.long).view(-1)\n",
    "\n",
    "\n",
    "    valid_mask = SL >= 0\n",
    "    SL = SL[valid_mask]\n",
    "    SL = SL[:XG.shape[0]]\n",
    "\n",
    "    \n",
    "    AG_combined=torch.cat([edge_index+i*num_nodes for i, edge_index in enumerate (AG_list)], dim=1)\n",
    "\n",
    "    \n",
    "\n",
    "    return XG, AG_combined, SL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "5cbcadb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_out_class(features, adjacency_matrix):\n",
    "    features_tensor=torch.tensor(features,dtype=torch.float)\n",
    "    adjacency_tensor=torch.tensor(adjacency_matrix,dtype=torch.long)\n",
    "\n",
    "    if adjacency_tensor.ndim==2 and adjacency_tensor.shape[0]==adjacency_tensor.shape[1]:\n",
    "        adjacency_tensor=torch.nonzero(adjacency_tensor, as_tuple=False).t()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits=f(features_tensor, adjacency_tensor)\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "    \n",
    "    return predictions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "b614d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_out_vector(features, adjacency_matrix):\n",
    "    features_tensor=torch.tensor(features,dtype=torch.float)\n",
    "    adjacency_tensor=torch.tensor(adjacency_matrix,dtype=torch.long)\n",
    "\n",
    "    if adjacency_tensor.ndim==2 and adjacency_tensor.shape[0]==adjacency_tensor.shape[1]:\n",
    "        adjacency_tensor=torch.nonzero(adjacency_tensor, as_tuple=False).t()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        logits=f(features_tensor, adjacency_tensor)\n",
    "\n",
    "    return logits.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "2dce9fa5-45e3-465b-bd18-186cd3768b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def api(model, data, mask):\n",
    "    model.eval()\n",
    "    out=model(data.x, data.edge_index)\n",
    "    pred=out[mask].argmax(dim=1)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "684c7fc4-39e8-4716-8ab3-0a11a86fefdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(victim_model, extracted_model,data, mask):\n",
    "    original_preds_labels=api(victim_model,data,mask)\n",
    "    extracted_preds_labels=api(extracted_model,data,mask)\n",
    "    score=accuracy_score(original_preds_labels, extracted_preds_labels)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "173373ed-11fc-4885-b13c-b4a751b0b48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f(victim_model,extraction_model,data,mask,times):\n",
    "    list_out=[]\n",
    "    for i in range(times):\n",
    "        pred=eval(victim_model,extraction_model,data,mask)\n",
    "        list_out.append(pred)\n",
    "    \n",
    "    return sum(list_out)/len(list_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "ce8100c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_center_node_in_subgraph(center_global_idx, node_mapping):\n",
    "    center_subgraph_idx = node_mapping.tolist().index(center_global_idx)\n",
    "    return center_subgraph_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "08190b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_nodes(Gc, api_out_vector, F, M, C, rho):\n",
    "    A,X=Gc\n",
    "    L=api_out_vector(X, A)\n",
    "    center_idx=find_center_node_in_subgraph(center_node,node_mapping)\n",
    "    \n",
    "    for node in range(A.shape[0]):\n",
    "        if node!=center_idx:\n",
    "            for c in range(C):\n",
    "                kl_div = np.exp(L[node][c]) * (L[node][c] - L[center_idx][c])\n",
    "                \n",
    "                if kl_div > 0:\n",
    "                    print(kl_div)\n",
    "                    num_new_nodes = int(kl_div * rho * np.log1p(A[node].sum())) \n",
    "                    print(num_new_nodes)\n",
    "                    for _ in range(num_new_nodes):\n",
    "                        new_node = A.shape[0]\n",
    "                        \n",
    "                        new_adj_row = np.zeros((1, A.shape[1]))\n",
    "                        A = np.vstack([A, new_adj_row])\n",
    "                        \n",
    "                        new_adj_col = np.zeros((A.shape[0], 1))\n",
    "                        A = np.hstack([A, new_adj_col])\n",
    "                        \n",
    "                        A[node, new_node] = 1\n",
    "                        A[new_node, node] = 1\n",
    "                        \n",
    "                        feature_count = np.random.choice(len(M[c]), p=M[c])  \n",
    "                        new_features = np.zeros_like(F[c])\n",
    "                        chosen_features = np.random.choice(len(F[c]), size=feature_count, p=F[c])  \n",
    "                        new_features[chosen_features] = 1 \n",
    "                        \n",
    "                        X = np.vstack([X, new_features])\n",
    "    \n",
    "    Gc=(A,X)\n",
    "    return Gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "630a1c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gnn/lib/python3.9/site-packages/torch_geometric/data/dataset.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
      "/opt/anaconda3/envs/gnn/lib/python3.9/site-packages/torch_geometric/data/dataset.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
      "/opt/anaconda3/envs/gnn/lib/python3.9/site-packages/torch_geometric/io/fs.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location)\n"
     ]
    }
   ],
   "source": [
    "dataset=load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "52d66cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "4e087e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=data.y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "8583c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "5a697e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features=data.x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "54d4c85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "F,M=get_distribution(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "b8e2820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "runturns=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "4ec4096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=GCN_Victim(data.x.shape[1],dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "57bb13d0-e87e-4c64-8ff6-801719957671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 1.94196\n",
      "Epoch 20, Loss: 0.17810\n",
      "Epoch 30, Loss: 0.03975\n",
      "Epoch 40, Loss: 0.00255\n",
      "Epoch 50, Loss: 0.00162\n",
      "Epoch 60, Loss: 0.00229\n",
      "Epoch 70, Loss: 0.00313\n",
      "Epoch 80, Loss: 0.00359\n",
      "Epoch 90, Loss: 0.00403\n",
      "Epoch 100, Loss: 0.00405\n",
      "Epoch 110, Loss: 0.00390\n",
      "Epoch 120, Loss: 0.00375\n",
      "Epoch 130, Loss: 0.00358\n",
      "Epoch 140, Loss: 0.00339\n",
      "Epoch 150, Loss: 0.00323\n",
      "Epoch 160, Loss: 0.00313\n",
      "Epoch 170, Loss: 0.00306\n",
      "Epoch 180, Loss: 0.00302\n",
      "Epoch 190, Loss: 0.00297\n",
      "Epoch 200, Loss: 0.00293\n"
     ]
    }
   ],
   "source": [
    "train_Victim(f,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "276c03f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "As, Xs, center_node, node_mapping=get_2hop_subgraph(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "4c18de33",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gs=(As,Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "1fde608b-a09e-4640-a8d2-352dadcea63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of the node is 1805\n"
     ]
    }
   ],
   "source": [
    "print(f\"The index of the node is {center_node}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "01016b94-1bb2-4077-90a9-e933e00669be",
   "metadata": {},
   "outputs": [],
   "source": [
    "XG, AG, SL=SubgraphSamplingAlgorithm(Gs,F, M, n=10, C=dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "1b7169d0-e811-4a91-bdf0-d78394dbd74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=GCN_Extraction(XG.shape[1], dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "e3c33d61-191a-4c43-ab13-6429fd65c87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 1.96491\n",
      "Epoch 20, Loss: 0.80763\n",
      "Epoch 30, Loss: 0.13576\n",
      "Epoch 40, Loss: 0.02696\n",
      "Epoch 50, Loss: 0.01270\n",
      "Epoch 60, Loss: 0.01068\n",
      "Epoch 70, Loss: 0.01155\n",
      "Epoch 80, Loss: 0.01318\n",
      "Epoch 90, Loss: 0.01454\n",
      "Epoch 100, Loss: 0.01502\n",
      "Epoch 110, Loss: 0.01468\n",
      "Epoch 120, Loss: 0.01394\n",
      "Epoch 130, Loss: 0.01312\n",
      "Epoch 140, Loss: 0.01235\n",
      "Epoch 150, Loss: 0.01171\n",
      "Epoch 160, Loss: 0.01116\n",
      "Epoch 170, Loss: 0.01069\n",
      "Epoch 180, Loss: 0.01028\n",
      "Epoch 190, Loss: 0.00991\n",
      "Epoch 200, Loss: 0.00957\n",
      "Epoch 210, Loss: 0.00927\n",
      "Epoch 220, Loss: 0.00899\n",
      "Epoch 230, Loss: 0.00874\n",
      "Epoch 240, Loss: 0.00850\n",
      "Epoch 250, Loss: 0.00829\n",
      "Epoch 260, Loss: 0.00810\n",
      "Epoch 270, Loss: 0.00792\n",
      "Epoch 280, Loss: 0.00776\n",
      "Epoch 290, Loss: 0.00760\n",
      "Epoch 300, Loss: 0.00746\n",
      "Epoch 310, Loss: 0.00734\n",
      "Epoch 320, Loss: 0.00722\n",
      "Epoch 330, Loss: 0.00711\n",
      "Epoch 340, Loss: 0.00700\n",
      "Epoch 350, Loss: 0.00691\n",
      "Epoch 360, Loss: 0.00682\n",
      "Epoch 370, Loss: 0.00673\n",
      "Epoch 380, Loss: 0.00666\n",
      "Epoch 390, Loss: 0.00659\n",
      "Epoch 400, Loss: 0.00652\n"
     ]
    }
   ],
   "source": [
    "train_Extraction(g,XG,AG,SL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "50fd26b9-00b1-40af-b1af-0e2a9355e54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7999999999999985\n"
     ]
    }
   ],
   "source": [
    "print(get_f(f,g,data,data.val_mask,runturns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "3f21aab2-b4fe-4554-ae00-edf916102294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15803975\n",
      "0\n",
      "2.913445\n",
      "4\n",
      "0.06019092\n",
      "0\n",
      "0.0059899776\n",
      "0\n",
      "0.080194116\n",
      "0\n",
      "0.25092846\n",
      "0\n",
      "0.00054511946\n",
      "0\n",
      "1.7204035e-05\n",
      "0\n",
      "0.0004789889\n",
      "0\n",
      "6.9592375e-08\n",
      "0\n",
      "0.0001668116\n",
      "0\n",
      "0.0021905038\n",
      "0\n",
      "4.0330793e-05\n",
      "0\n",
      "0.0029407365\n",
      "0\n",
      "0.0022450245\n",
      "0\n",
      "0.0009100209\n",
      "0\n",
      "0.001931866\n",
      "0\n",
      "8.740703e-05\n",
      "0\n",
      "0.0003179343\n",
      "0\n",
      "1.4388102e-06\n",
      "0\n",
      "0.0013771738\n",
      "0\n",
      "0.0023787993\n",
      "0\n",
      "1.9840028e-05\n",
      "0\n",
      "2.410854e-05\n",
      "0\n",
      "0.0026588137\n",
      "0\n",
      "0.001846148\n",
      "0\n",
      "0.0018364972\n",
      "0\n",
      "0.0015189915\n",
      "0\n",
      "0.0029809498\n",
      "0\n",
      "1.2076904e-05\n",
      "0\n",
      "0.0027813877\n",
      "0\n",
      "0.002598373\n",
      "0\n",
      "0.0025588414\n",
      "0\n",
      "0.13850905\n",
      "0\n",
      "0.10863025\n",
      "0\n",
      "0.015259831\n",
      "0\n",
      "0.036703207\n",
      "0\n",
      "0.006736813\n",
      "0\n",
      "0.2803359\n",
      "0\n",
      "0.0066120243\n",
      "0\n",
      "6.27215\n",
      "13\n",
      "0.00027915617\n",
      "0\n",
      "0.0049441042\n",
      "0\n",
      "0.005613043\n",
      "0\n",
      "0.0028533498\n",
      "0\n",
      "0.03101839\n",
      "0\n",
      "4.570126\n",
      "10\n",
      "0.0028214774\n",
      "0\n",
      "2.1524624e-05\n",
      "0\n",
      "0.0034956774\n",
      "0\n",
      "0.024788411\n",
      "0\n",
      "0.031452004\n",
      "0\n",
      "0.9555662\n",
      "2\n",
      "0.007875177\n",
      "0\n",
      "0.0008095057\n",
      "0\n",
      "0.0013002433\n",
      "0\n",
      "0.031275857\n",
      "0\n",
      "0.03832355\n",
      "0\n",
      "0.035310272\n",
      "0\n",
      "0.019939762\n",
      "0\n",
      "0.02748624\n",
      "0\n",
      "0.0008788744\n",
      "0\n",
      "0.039570834\n",
      "0\n",
      "0.0021767856\n",
      "0\n",
      "2.1378623e-06\n",
      "0\n",
      "0.000105253035\n",
      "0\n",
      "0.0029408562\n",
      "0\n",
      "0.00053188246\n",
      "0\n",
      "0.0002721294\n",
      "0\n",
      "0.00060562586\n",
      "0\n",
      "4.046694e-07\n",
      "0\n",
      "0.0007138825\n",
      "0\n",
      "0.0014781073\n",
      "0\n",
      "0.002680256\n",
      "0\n",
      "0.0014078784\n",
      "0\n",
      "1.4109793e-05\n",
      "0\n",
      "0.0024119997\n",
      "0\n",
      "0.0051530167\n",
      "0\n",
      "0.013670537\n",
      "0\n",
      "0.0018599287\n",
      "0\n",
      "0.0014303147\n",
      "0\n",
      "2.1818822e-05\n",
      "0\n",
      "0.0030735543\n",
      "0\n",
      "0.24198669\n",
      "0\n",
      "2.3219984\n",
      "3\n",
      "0.013296373\n",
      "0\n",
      "0.007365332\n",
      "0\n",
      "0.058983196\n",
      "0\n",
      "0.49881622\n",
      "1\n",
      "0.0029298568\n",
      "0\n",
      "0.02943896\n",
      "0\n",
      "0.14590527\n",
      "0\n",
      "0.0028803963\n",
      "0\n",
      "0.0019915882\n",
      "0\n",
      "0.0003050762\n",
      "0\n",
      "0.025943961\n",
      "0\n",
      "0.0028719967\n",
      "0\n",
      "0.0009822391\n",
      "0\n",
      "1.4197643e-05\n",
      "0\n",
      "0.00021389408\n",
      "0\n",
      "7.620414e-10\n",
      "0\n",
      "0.0001810121\n",
      "0\n",
      "8.160562e-05\n",
      "0\n",
      "0.0007029836\n",
      "0\n",
      "4.944219e-07\n",
      "0\n",
      "0.00056204764\n",
      "0\n",
      "0.28526995\n",
      "0\n",
      "0.17769384\n",
      "0\n",
      "0.0012383551\n",
      "0\n",
      "0.001701479\n",
      "0\n",
      "0.0001949321\n",
      "0\n",
      "0.022615446\n",
      "0\n",
      "0.0029071418\n",
      "0\n",
      "0.0016041033\n",
      "0\n",
      "2.6925914e-05\n",
      "0\n",
      "0.000116746465\n",
      "0\n",
      "0.0015443291\n",
      "0\n",
      "6.420409e-06\n",
      "0\n",
      "0.00013225984\n",
      "0\n",
      "0.01789248\n",
      "0\n",
      "0.029801743\n",
      "0\n",
      "0.00667174\n",
      "0\n",
      "0.0075907647\n",
      "0\n",
      "0.0001481612\n",
      "0\n",
      "0.010370008\n",
      "0\n",
      "0.0036364319\n",
      "0\n",
      "0.0060032452\n",
      "0\n",
      "0.00027466993\n",
      "0\n",
      "0.0027121662\n",
      "0\n",
      "1.7369779e-05\n",
      "0\n",
      "0.010897612\n",
      "0\n",
      "2.0050647e-06\n",
      "0\n",
      "0.0012932243\n",
      "0\n",
      "0.000447202\n",
      "0\n",
      "3.093072e-06\n",
      "0\n",
      "0.00058640545\n",
      "0\n",
      "0.01748703\n",
      "0\n",
      "0.04434147\n",
      "0\n",
      "0.009554061\n",
      "0\n",
      "0.012938332\n",
      "0\n",
      "0.00059074734\n",
      "0\n",
      "0.0354647\n",
      "0\n",
      "0.0020272403\n",
      "0\n",
      "0.0010425423\n",
      "0\n",
      "0.00024601826\n",
      "0\n",
      "0.001716831\n",
      "0\n",
      "2.892456e-06\n",
      "0\n",
      "0.0017024679\n",
      "0\n",
      "0.0023162612\n",
      "0\n",
      "3.5789224e-06\n",
      "0\n",
      "0.017509526\n",
      "0\n",
      "0.024286637\n",
      "0\n",
      "0.0116533665\n",
      "0\n",
      "0.025911301\n",
      "0\n",
      "0.0011223754\n",
      "0\n",
      "0.07438761\n",
      "0\n",
      "0.0011277564\n",
      "0\n",
      "3.355588e-05\n",
      "0\n",
      "0.00010724095\n",
      "0\n",
      "0.0014904779\n",
      "0\n",
      "0.00017803386\n",
      "0\n",
      "0.0008190287\n",
      "0\n",
      "5.09559e-07\n",
      "0\n",
      "0.00012489055\n",
      "0\n",
      "2.3976887e-05\n",
      "0\n",
      "0.0011335831\n",
      "0\n",
      "2.8299617e-05\n",
      "0\n",
      "0.00038989997\n",
      "0\n",
      "0.016003259\n",
      "0\n",
      "0.057785492\n",
      "0\n",
      "0.000180154\n",
      "0\n",
      "0.0014292699\n",
      "0\n",
      "6.400862e-05\n",
      "0\n",
      "0.03122055\n",
      "0\n",
      "0.0022407295\n",
      "0\n",
      "5.401453e-05\n",
      "0\n",
      "0.0025821298\n",
      "0\n",
      "0.18230993\n",
      "0\n",
      "2.4381297\n",
      "3\n",
      "0.015247013\n",
      "0\n",
      "0.0053299055\n",
      "0\n",
      "0.045027204\n",
      "0\n",
      "0.35747966\n",
      "1\n",
      "0.006254141\n",
      "0\n",
      "0.050780937\n",
      "0\n",
      "0.0005523906\n",
      "0\n",
      "0.00023295399\n",
      "0\n",
      "2.1270407e-05\n",
      "0\n",
      "0.0048984885\n",
      "0\n",
      "0.071338505\n",
      "0\n",
      "0.14532019\n",
      "0\n",
      "0.0031502363\n",
      "0\n",
      "0.0044953288\n",
      "0\n",
      "0.0011565875\n",
      "0\n",
      "0.11156965\n",
      "0\n",
      "0.013560108\n",
      "0\n",
      "0.006058573\n",
      "0\n",
      "0.0025474916\n",
      "0\n",
      "0.017373834\n",
      "0\n",
      "9.8831966e-05\n",
      "0\n",
      "0.019763652\n",
      "0\n",
      "0.0041387337\n",
      "0\n",
      "0.002894016\n",
      "0\n",
      "0.0009474686\n",
      "0\n",
      "0.0034299106\n",
      "0\n",
      "1.6784166e-05\n",
      "0\n",
      "0.0056946767\n",
      "0\n",
      "0.015262918\n",
      "0\n",
      "5.174597\n",
      "14\n",
      "0.0014172648\n",
      "0\n",
      "0.0016378382\n",
      "0\n",
      "0.009332497\n",
      "0\n",
      "0.101636544\n",
      "0\n",
      "0.0014341685\n",
      "0\n",
      "0.00033864815\n",
      "0\n",
      "0.0024843938\n",
      "0\n",
      "9.727243e-07\n",
      "0\n",
      "0.00027314638\n",
      "0\n",
      "0.0036733227\n",
      "0\n",
      "0.0016187651\n",
      "0\n",
      "0.0005482446\n",
      "0\n",
      "0.0009261987\n",
      "0\n",
      "1.2570158e-06\n",
      "0\n",
      "0.0023562415\n",
      "0\n",
      "0.0009820014\n",
      "0\n",
      "1.1163834e-05\n",
      "0\n",
      "0.0003276141\n",
      "0\n",
      "6.6806107e-09\n",
      "0\n",
      "0.0066120243\n",
      "0\n",
      "6.27215\n",
      "13\n",
      "0.00027915617\n",
      "0\n",
      "0.0049441042\n",
      "0\n",
      "0.005613043\n",
      "0\n",
      "0.00073836534\n",
      "0\n",
      "0.0015551357\n",
      "0\n",
      "0.0027796922\n",
      "0\n",
      "0.0014288697\n",
      "0\n",
      "1.5011848e-05\n",
      "0\n",
      "0.0025237044\n",
      "0\n",
      "0.0016500661\n",
      "0\n",
      "0.0003720752\n",
      "0\n",
      "0.0014879423\n",
      "0\n",
      "2.316799e-06\n",
      "0\n",
      "0.0014679192\n",
      "0\n",
      "0.0002732552\n",
      "0\n",
      "5.524701\n",
      "24\n",
      "5.023107e-06\n",
      "0\n",
      "9.5017285e-06\n",
      "0\n",
      "0.0011275185\n",
      "0\n",
      "0.32637125\n",
      "0\n",
      "3.536621\n",
      "4\n",
      "0.058257394\n",
      "0\n",
      "0.005929515\n",
      "0\n",
      "0.25434503\n",
      "0\n",
      "0.43217483\n",
      "1\n",
      "0.019567331\n",
      "0\n",
      "0.8484053\n",
      "2\n",
      "0.0013052147\n",
      "0\n",
      "8.039996e-05\n",
      "0\n",
      "0.00022594394\n",
      "0\n",
      "0.014508629\n",
      "0\n",
      "0.005436466\n",
      "0\n",
      "0.00045124054\n",
      "0\n",
      "0.00057063444\n",
      "0\n",
      "0.002476439\n",
      "0\n",
      "1.5310975e-06\n",
      "0\n",
      "0.00018725895\n",
      "0\n",
      "0.0006851017\n",
      "0\n",
      "9.497951e-06\n",
      "0\n",
      "0.0022637607\n",
      "0\n",
      "0.0010612526\n",
      "0\n",
      "0.0036213938\n",
      "0\n",
      "0.0045602517\n",
      "0\n",
      "1.0839165e-05\n",
      "0\n",
      "0.0012224462\n",
      "0\n",
      "0.00203269\n",
      "0\n",
      "0.0018884151\n",
      "0\n",
      "0.0013420073\n",
      "0\n",
      "0.003097298\n",
      "0\n",
      "1.2088654e-05\n",
      "0\n",
      "0.003087207\n",
      "0\n",
      "0.001129852\n",
      "0\n",
      "0.007012935\n",
      "0\n",
      "0.000108767104\n",
      "0\n",
      "0.00012652048\n",
      "0\n",
      "1.6317881e-06\n",
      "0\n",
      "0.00083455356\n",
      "0\n",
      "0.0029408562\n",
      "0\n",
      "0.0028618362\n",
      "0\n",
      "0.0033500216\n",
      "0\n",
      "0.00083900185\n",
      "0\n",
      "0.0004022837\n",
      "0\n",
      "0.0022676478\n",
      "0\n",
      "2.7353994e-06\n",
      "0\n",
      "0.001225382\n",
      "0\n",
      "0.0030292927\n",
      "0\n",
      "0.0038857649\n",
      "0\n",
      "0.0032392212\n",
      "0\n",
      "0.0026926259\n",
      "0\n",
      "1.661143e-05\n",
      "0\n",
      "0.0018381329\n",
      "0\n",
      "0.0010824606\n",
      "0\n",
      "0.0069847167\n",
      "0\n",
      "0.00010680952\n",
      "0\n",
      "0.00012579733\n",
      "0\n",
      "1.6313436e-06\n",
      "0\n",
      "0.0008527052\n",
      "0\n",
      "0.03145131\n",
      "0\n",
      "0.034226704\n",
      "0\n",
      "0.009969984\n",
      "0\n",
      "0.038799893\n",
      "0\n",
      "0.0018705208\n",
      "0\n",
      "0.12912281\n",
      "0\n",
      "0.002112973\n",
      "0\n",
      "1.6509086e-06\n",
      "0\n",
      "2.6004827e-06\n",
      "0\n",
      "0.006535327\n",
      "0\n",
      "5.3974156\n",
      "17\n",
      "0.00040974203\n",
      "0\n",
      "0.00047461197\n",
      "0\n",
      "0.0031793397\n",
      "0\n",
      "0.03828548\n",
      "0\n",
      "4.282934\n",
      "9\n",
      "0.004566677\n",
      "0\n",
      "7.749085e-05\n",
      "0\n",
      "0.0048312764\n",
      "0\n",
      "0.032951787\n",
      "0\n",
      "0.009667363\n",
      "0\n",
      "4.341952\n",
      "13\n",
      "0.00046035566\n",
      "0\n",
      "0.00033468884\n",
      "0\n",
      "0.0058170757\n",
      "0\n",
      "0.0020640513\n",
      "0\n",
      "0.0009267727\n",
      "0\n",
      "0.00027785878\n",
      "0\n",
      "0.0025258646\n",
      "0\n",
      "5.4780235e-06\n",
      "0\n",
      "0.0038362776\n",
      "0\n",
      "0.002357435\n",
      "0\n",
      "0.0013859696\n",
      "0\n",
      "0.0008213418\n",
      "0\n",
      "0.00019310784\n",
      "0\n",
      "0.0013234216\n",
      "0\n",
      "1.918647e-06\n",
      "0\n",
      "0.001154497\n",
      "0\n",
      "0.0028257398\n",
      "0\n",
      "0.0022377467\n",
      "0\n",
      "2.7950058e-05\n",
      "0\n",
      "0.002383932\n",
      "0\n",
      "8.768706e-06\n",
      "0\n",
      "0.001885733\n",
      "0\n",
      "6.9715745e-05\n",
      "0\n",
      "0.0009516523\n",
      "0\n",
      "0.00010161806\n",
      "0\n",
      "0.00088377245\n",
      "0\n",
      "4.3120045e-07\n",
      "0\n",
      "0.00038664977\n",
      "0\n",
      "0.0028256201\n",
      "0\n",
      "0.00012143753\n",
      "0\n",
      "0.0008567311\n",
      "0\n",
      "2.956207e-05\n",
      "0\n",
      "4.0143197e-05\n",
      "0\n",
      "1.5949314e-07\n",
      "0\n",
      "0.0036404533\n",
      "0\n",
      "0.0005260629\n",
      "0\n",
      "0.00037870227\n",
      "0\n",
      "0.0042067417\n",
      "0\n",
      "4.9190817e-06\n",
      "0\n",
      "0.0030629835\n",
      "0\n",
      "0.0015305183\n",
      "0\n",
      "2.4455248e-05\n",
      "0\n",
      "0.00013317731\n",
      "0\n",
      "0.0016692242\n",
      "0\n",
      "0.00024614617\n",
      "0\n",
      "0.0002161244\n",
      "0\n",
      "0.0013789614\n",
      "0\n",
      "1.5146638e-06\n",
      "0\n",
      "0.000810845\n",
      "0\n",
      "0.010684333\n",
      "0\n",
      "0.007352459\n",
      "0\n",
      "0.00025061736\n",
      "0\n",
      "0.0007795001\n",
      "0\n",
      "3.5378064e-06\n",
      "0\n",
      "0.00174838\n",
      "0\n",
      "0.002085663\n",
      "0\n",
      "0.029442456\n",
      "0\n",
      "0.15298428\n",
      "0\n",
      "0.0029889685\n",
      "0\n",
      "0.0016577176\n",
      "0\n",
      "0.00026082748\n",
      "0\n",
      "0.02100631\n",
      "0\n",
      "0.62426704\n",
      "1\n",
      "1.0410165\n",
      "2\n",
      "0.0019972434\n",
      "0\n",
      "0.0011198396\n",
      "0\n",
      "0.0015011276\n",
      "0\n",
      "0.06528915\n",
      "0\n",
      "0.019332737\n",
      "0\n",
      "0.0693722\n",
      "0\n",
      "0.00022469595\n",
      "0\n",
      "0.001630644\n",
      "0\n",
      "9.050465e-05\n",
      "0\n",
      "0.03805264\n",
      "0\n",
      "0.028532073\n",
      "0\n",
      "0.15006842\n",
      "0\n",
      "0.0034539786\n",
      "0\n",
      "0.0019596743\n",
      "0\n",
      "0.00031842885\n",
      "0\n",
      "0.02426908\n",
      "0\n",
      "0.2852515\n",
      "0\n",
      "1.6623533\n",
      "2\n",
      "0.0067234146\n",
      "0\n",
      "0.010401242\n",
      "0\n",
      "0.0419075\n",
      "0\n",
      "0.6718518\n",
      "1\n",
      "0.017872375\n",
      "0\n",
      "0.65161735\n",
      "1\n",
      "0.0010021579\n",
      "0\n",
      "8.4756844e-05\n",
      "0\n",
      "0.00016872617\n",
      "0\n",
      "0.013543444\n",
      "0\n",
      "0.0028469127\n",
      "0\n",
      "0.003941189\n",
      "0\n",
      "0.0032022581\n",
      "0\n",
      "0.002807224\n",
      "0\n",
      "1.7446555e-05\n",
      "0\n",
      "0.002007886\n",
      "0\n",
      "0.0030465245\n",
      "0\n",
      "2.1132179e-05\n",
      "0\n",
      "0.0005569453\n",
      "0\n",
      "0.00276957\n",
      "0\n",
      "4.7736235e-06\n",
      "0\n",
      "0.003001045\n",
      "0\n",
      "0.0029393018\n",
      "0\n",
      "0.0007707346\n",
      "0\n",
      "0.00082877366\n",
      "0\n",
      "0.00028981597\n",
      "0\n",
      "3.031275e-07\n",
      "0\n",
      "0.00058713515\n",
      "0\n",
      "0.00057796726\n",
      "0\n",
      "0.003370821\n",
      "0\n",
      "0.0011362003\n",
      "0\n",
      "3.9367324e-06\n",
      "0\n",
      "5.5337863e-05\n",
      "0\n",
      "0.0019530253\n",
      "0\n",
      "0.0017787011\n",
      "0\n",
      "0.0014943776\n",
      "0\n",
      "0.0028337005\n",
      "0\n",
      "1.0231426e-05\n",
      "0\n",
      "0.0022338368\n",
      "0\n",
      "0.0028911228\n",
      "0\n",
      "0.0037898817\n",
      "0\n",
      "0.0011797511\n",
      "0\n",
      "0.0006193439\n",
      "0\n",
      "0.0024993268\n",
      "0\n",
      "3.6388324e-06\n",
      "0\n",
      "0.0012012543\n",
      "0\n",
      "0.0024431401\n",
      "0\n",
      "5.7258912e-06\n",
      "0\n",
      "0.000163325\n",
      "0\n",
      "2.0876823e-06\n",
      "0\n",
      "0.0005741931\n",
      "0\n",
      "6.5311646e-08\n",
      "0\n",
      "0.000976533\n",
      "0\n",
      "0.004754725\n",
      "0\n",
      "0.0047010332\n",
      "0\n",
      "0.0031154712\n",
      "0\n",
      "0.0070317797\n",
      "0\n",
      "3.5014735e-05\n",
      "0\n",
      "0.004853531\n",
      "0\n",
      "0.014759427\n",
      "0\n",
      "0.0022505147\n",
      "0\n",
      "0.00074576813\n",
      "0\n",
      "0.0043748952\n",
      "0\n",
      "5.477323e-06\n",
      "0\n",
      "0.0017545624\n",
      "0\n",
      "0.0009799032\n",
      "0\n",
      "0.00031431895\n",
      "0\n",
      "6.408703e-05\n",
      "0\n",
      "0.00051313115\n",
      "0\n",
      "9.989176e-09\n",
      "0\n",
      "0.0014904779\n",
      "0\n",
      "0.00017803386\n",
      "0\n",
      "0.0008190287\n",
      "0\n",
      "5.09559e-07\n",
      "0\n",
      "0.00012489055\n",
      "0\n",
      "0.039164063\n",
      "0\n",
      "0.047116973\n",
      "0\n",
      "0.020283181\n",
      "0\n",
      "0.010236528\n",
      "0\n",
      "0.0004222118\n",
      "0\n",
      "0.014911961\n",
      "0\n",
      "0.03811\n",
      "0\n",
      "0.09431919\n",
      "0\n",
      "0.013446913\n",
      "0\n",
      "0.017393397\n",
      "0\n",
      "0.002046597\n",
      "0\n",
      "0.08947902\n",
      "0\n",
      "0.036054\n",
      "0\n",
      "0.025134912\n",
      "0\n",
      "0.016094217\n",
      "0\n",
      "0.032748044\n",
      "0\n",
      "0.00079332123\n",
      "0\n",
      "0.043581687\n",
      "0\n",
      "0.001843175\n",
      "0\n",
      "0.00016021398\n",
      "0\n",
      "0.0042152177\n",
      "0\n",
      "5.704285e-06\n",
      "0\n",
      "0.0077801524\n",
      "0\n",
      "0.0047073173\n",
      "0\n",
      "0.002552337\n",
      "0\n",
      "0.0018758186\n",
      "0\n",
      "0.013169647\n",
      "0\n",
      "5.760346e-05\n",
      "0\n",
      "0.014936687\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "Gs_with_approximated_nodes = approximate_nodes(Gs, api_out_vector, F, M, C=dataset.num_classes,rho=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "31210e99-410f-4e0c-9118-747b408c906c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of tensors with algo1((119, 119), (119, 1433))\n",
      "The size of tensors with algo2((260, 260), (260, 1433))\n"
     ]
    }
   ],
   "source": [
    "print(f\"The size of tensors with algo1{Gs[0].shape,Gs[1].shape}\")\n",
    "print(f\"The size of tensors with algo2{Gs_with_approximated_nodes[0].shape,Gs_with_approximated_nodes[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "fbf7c6a3-ffc6-4a4e-94cf-2bbe15f7a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "XG1, AG1, SL1=SubgraphSamplingAlgorithm(Gs_with_approximated_nodes,F, M, n=10, C=dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "e3d14421-d273-4f81-8292-79023bbdaa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1=GCN_Extraction(XG1.shape[1], dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "8b08199e-6de5-4593-9afd-534f9460e3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 1.94871\n",
      "Epoch 20, Loss: 0.83225\n",
      "Epoch 30, Loss: 0.16972\n",
      "Epoch 40, Loss: 0.03132\n",
      "Epoch 50, Loss: 0.01448\n",
      "Epoch 60, Loss: 0.01202\n",
      "Epoch 70, Loss: 0.01278\n",
      "Epoch 80, Loss: 0.01418\n",
      "Epoch 90, Loss: 0.01528\n",
      "Epoch 100, Loss: 0.01560\n",
      "Epoch 110, Loss: 0.01522\n",
      "Epoch 120, Loss: 0.01445\n",
      "Epoch 130, Loss: 0.01358\n",
      "Epoch 140, Loss: 0.01279\n",
      "Epoch 150, Loss: 0.01213\n",
      "Epoch 160, Loss: 0.01158\n",
      "Epoch 170, Loss: 0.01111\n",
      "Epoch 180, Loss: 0.01068\n",
      "Epoch 190, Loss: 0.01030\n",
      "Epoch 200, Loss: 0.00996\n",
      "Epoch 210, Loss: 0.00965\n",
      "Epoch 220, Loss: 0.00937\n",
      "Epoch 230, Loss: 0.00911\n",
      "Epoch 240, Loss: 0.00887\n",
      "Epoch 250, Loss: 0.00865\n",
      "Epoch 260, Loss: 0.00846\n",
      "Epoch 270, Loss: 0.00827\n",
      "Epoch 280, Loss: 0.00810\n",
      "Epoch 290, Loss: 0.00795\n",
      "Epoch 300, Loss: 0.00780\n",
      "Epoch 310, Loss: 0.00767\n",
      "Epoch 320, Loss: 0.00754\n",
      "Epoch 330, Loss: 0.00742\n",
      "Epoch 340, Loss: 0.00731\n",
      "Epoch 350, Loss: 0.00721\n",
      "Epoch 360, Loss: 0.00712\n",
      "Epoch 370, Loss: 0.00703\n",
      "Epoch 380, Loss: 0.00694\n",
      "Epoch 390, Loss: 0.00686\n",
      "Epoch 400, Loss: 0.00679\n"
     ]
    }
   ],
   "source": [
    "train_Extraction(g1,XG1,AG1,SL1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "ab2407ae-8f0b-4c7f-8b29-505c20a9796d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8119999999999987\n"
     ]
    }
   ],
   "source": [
    "print(get_f(f,g1,data,data.val_mask,runturns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9820597c-0c7d-4cb8-ae22-39d7b89bf924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
